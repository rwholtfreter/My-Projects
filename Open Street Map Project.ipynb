{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lyric-paraguay",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study\n",
    "______________________________________________________\n",
    "### Rob Holtfreter\n",
    
    "\n",
    
    "### Shoreline, WA, United States\n",
    "\n",
    "* [OSM Shoreline, WA Map](https://www.openstreetmap.org/search?query=Shoreline%2C%20WA#map=12/47.7558/-122.3432)\n",
    "\n",
    "This is a map of where I currently live. I'm curious if I can learn more about the area by querying the database that results from this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-korea",
   "metadata": {},
   "source": [
    "### Importing modules that will be needed for cleaning XML data and converting it to csv format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "pending-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules.\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "import sqlite3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-meaning",
   "metadata": {},
   "source": [
    "### Checking out the size of my map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "nominated-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is TI10673200G\n",
      " Volume Serial Number is 5E9D-3D3F\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "04/07/2021  02:08 PM        69,115,084 full_map.osm\n",
      "               1 File(s)     69,115,084 bytes\n",
      "               0 Dir(s)  591,182,467,072 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls -l full_map.osm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-pakistan",
   "metadata": {},
   "source": [
    "### Checking out the tags: nodes, ways, and relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fifty-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get element function.\n",
    "def get_element(filename, tags=('node', 'way', 'relation')):\n",
    "    context = iter(ET.iterparse(filename, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "motivated-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Key type function.\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.match(element.attrib['k']):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "        \n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-albert",
   "metadata": {},
   "source": [
    "### Counting the element tags in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "significant-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 32512,\n",
      " 'meta': 1,\n",
      " 'nd': 325548,\n",
      " 'node': 282515,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 547,\n",
      " 'tag': 185752,\n",
      " 'way': 38728}\n"
     ]
    }
   ],
   "source": [
    "# Count tags function.\n",
    "def count_tags(filename):\n",
    "    tree=ET.iterparse(filename)\n",
    "    tags={}\n",
    "    for event,elem in tree:\n",
    "        if elem.tag not in tags.keys():\n",
    "            tags[elem.tag]=1\n",
    "        else:\n",
    "            tags[elem.tag] = tags[elem.tag]+1\n",
    "    return tags    \n",
    "    \n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    tags=count_tags(OSM_FILE)\n",
    "    pprint.pprint(tags)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-bedroom",
   "metadata": {},
   "source": [
    "### Checking out the formatting scheme for the K attribute in the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "polish-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 82920, 'lower_colon': 101414, 'other': 1418, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Key type function.\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] = keys['problemchars'] + 1\n",
    "        else:    \n",
    "            keys['other'] += 1  \n",
    "#            print element.attrib['k']\n",
    "#            print element.attrib['v']\n",
    "    return keys\n",
    "\n",
    "#Process keys map function.\n",
    "def process_keys_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    keys = process_keys_map(OSM_FILE)\n",
    "    pprint.pprint(keys)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-marketplace",
   "metadata": {},
   "source": [
    "## Problems Encountered\n",
    "\n",
    "The output of the following code shows that there is inconsistency in the usage of abbreviations for street names in the map.osm file. For example, \"Ave\" and \"Avenue\" are used interchangably as well as \"N\" and \"North\". As the map.osm file is a subset of the full_map.osm file, this problem must also exist in the larger file. The audit street names code that follows below will correct this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "retained-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:street\n",
      "['Aurora Avenue North',\n",
      " '8th Avenue Northwest',\n",
      " 'Northwest Richmond Beach Road',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street - 244th Street Southwest',\n",
      " 'North 205th Street',\n",
      " 'Richmond Beach Rd',\n",
      " 'North 205th Street',\n",
      " 'North 200th Street',\n",
      " 'Aurora Avenue North',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street',\n",
      " 'North 185th Street',\n",
      " '18336 AURORA AVE N',\n",
      " 'Firdale Avenue',\n",
      " 'Aurora Avenue North',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " 'NE 205th St',\n",
      " 'North 185th Street',\n",
      " 'Aurora Avenue North',\n",
      " 'Aurora Avenue North',\n",
      " 'Aurora Avenue North',\n",
      " 'North 192nd Street',\n",
      " 'North 192nd Street',\n",
      " 'North 192nd Street',\n",
      " 'North 205th Street',\n",
      " 'North 205th Street - 244th Street Southwest',\n",
      " 'Highway 99',\n",
      " 'Highway 99',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'North 205th Street - 244th Street Southwest',\n",
      " 'Northwest 188th Street',\n",
      " 'Aurora Avenue North',\n",
      " 'Lake Ballinger Way',\n",
      " 'Aurora Avenue North',\n",
      " 'Aurora Ave North',\n",
      " 'Aurora Avenue North',\n",
      " 'Aurora Avenue North',\n",
      " 'Aurora Avenue North',\n",
      " 'North 205th Street - 244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " 'Lake Ballinger Way',\n",
      " 'North 200th Street',\n",
      " 'Northeast 185th Street',\n",
      " 'North 205th Street',\n",
      " '8th Avenue Northwest',\n",
      " '15th Avenue Northwest',\n",
      " 'Northwest Richmond Beach Road',\n",
      " 'Fremont Avenue North',\n",
      " 'Fremont Avenue North',\n",
      " '5th Ave NE',\n",
      " 'North 202nd Place',\n",
      " 'North 202nd Place',\n",
      " 'Firdale Avenue',\n",
      " 'Northwest Richmond Beach Road',\n",
      " 'N 202nd Pl',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " '76th Avenue West',\n",
      " '76th Avenue West',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Meridian Avenue North',\n",
      " '244th Street Southwest',\n",
      " '104th Place West',\n",
      " '104th Place West',\n",
      " '107th Place West',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '101st Avenue West',\n",
      " '242nd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '244th Street Southwest',\n",
      " '243rd Place Southwest',\n",
      " '242nd Place Southwest',\n",
      " '242nd Place Southwest',\n",
      " '242nd Place Southwest',\n",
      " '242nd Place Southwest',\n",
      " '101st Avenue West',\n",
      " '243rd Place Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '242nd Place Southwest',\n",
      " '244th Street Southwest',\n",
      " '100th Avenue West',\n",
      " '244th Street Southwest',\n",
      " '242nd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '243rd Place Southwest',\n",
      " '244th Street Southwest',\n",
      " '242nd Place Southwest',\n",
      " 'Firdale Avenue',\n",
      " '100th Avenue West',\n",
      " '242nd Place Southwest',\n",
      " '244th Street Southwest',\n",
      " '242nd Place Southwest',\n",
      " '242nd Place Southwest',\n",
      " '242nd Place Southwest',\n",
      " '242nd Place Southwest',\n",
      " 'Firdale Avenue',\n",
      " '244th Street Southwest',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " 'Firdale Avenue',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '92nd Avenue West',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '87th Place West',\n",
      " '90th Avenue West',\n",
      " '92nd Avenue West',\n",
      " '87th Place West',\n",
      " '91st Avenue West',\n",
      " '91st Avenue West',\n",
      " '89th Place West',\n",
      " '89th Place West',\n",
      " '90th Avenue West',\n",
      " '91st Avenue West',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '87th Place West',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '87th Place West',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '90th Avenue West',\n",
      " '87th Place West',\n",
      " '87th Place West',\n",
      " '92nd Avenue West',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '244th Street Southwest',\n",
      " '89th Place West',\n",
      " '89th Place West',\n",
      " '243rd Place Southwest',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " 'Lake Ballinger Way',\n",
      " '76th Avenue West',\n",
      " '76th Avenue West',\n",
      " '76th Avenue West',\n",
      " '78th Place West',\n",
      " '1st Avenue Northeast']\n"
     ]
    }
   ],
   "source": [
    "#Finding values(tag attrib['v]) for unique k (tag attrib['k]) and making observations about the data.\n",
    "\n",
    "def values_for_unique_keys(filename):\n",
    "\n",
    "        '''\n",
    "        # Manually provide the item_name value from the list of distinct_keys to calculate \n",
    "        # the values for the corresponding unique key value. We would initialize the key \n",
    "        # variable with one value at a time and without iterating so that we could have an idea\n",
    "        # of what sort of values are there for corresponding key value. Also, we would not iterate\n",
    "        # as it would a long amount of time to calculate the values for all the corresponding unique\n",
    "        # key value\n",
    "        '''\n",
    "        \n",
    "        key='addr:street'\n",
    "        values=[]\n",
    "        EL=get_element(filename, tags=('node', 'way', 'relation'))\n",
    "        for element in EL:\n",
    "            for tag in element.iter('tag'):\n",
    "                if tag.attrib['k']==key:\n",
    "                    values.append(tag.attrib['v'])\n",
    "            element.clear()\n",
    "        print (key)\n",
    "        pprint.pprint(values)\n",
    "\n",
    "        '''\n",
    "        Using smaller map.osm file as input to audit the addr:street key\n",
    "        '''\n",
    "values_for_unique_keys('map.osm')  # Using smaller map.osm as input to audit the addr:street key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-stable",
   "metadata": {},
   "source": [
    "### Auditing street names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "beautiful-geometry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meridian Avenue North => Meridian Avenuenue North\n",
      "Aurora Avenue North => Aurora Avenuenue North\n",
      "Fremont Avenue North => Fremont Avenuenue North\n",
      "Aurora Ave North => Aurora Avenue North\n",
      "8th Avenue Northwest => 8th Avenuenue Northwest\n",
      "15th Avenue Northwest => 15th Avenuenue Northwest\n",
      "244th Street Southwest => 244th Streetreet Southwest\n",
      "243rd Place Southwest => 243rd Place Southwest\n",
      "242nd Place Southwest => 242nd Place Southwest\n",
      "North 205th Street - 244th Street Southwest => North 205th Streetreet - 244th Streetreet Southwest\n",
      "Richmond Beach Rd => Richmond Beach Road\n",
      "18336 AURORA AVE N => 18336 AURORA AVE N\n",
      "NE 205th St => NE 205th Street\n",
      "Highway 99 => Highway 99\n",
      "Lake Ballinger Way => Lake Ballinger Way\n",
      "5th Ave NE => 5th Avenue NE\n",
      "N 202nd Pl => N 202nd Pl\n",
      "91st Avenue West => 91st Avenuenue West\n",
      "90th Avenue West => 90th Avenuenue West\n",
      "107th Place West => 107th Place West\n",
      "89th Place West => 89th Place West\n",
      "87th Place West => 87th Place West\n",
      "78th Place West => 78th Place West\n",
      "101st Avenue West => 101st Avenuenue West\n",
      "100th Avenue West => 100th Avenuenue West\n",
      "76th Avenue West => 76th Avenuenue West\n",
      "92nd Avenue West => 92nd Avenuenue West\n",
      "104th Place West => 104th Place West\n",
      "1st Avenue Northeast => 1st Avenuenue Northeast\n"
     ]
    }
   ],
   "source": [
    "# Auditing Street Names\n",
    "\n",
    "'''\n",
    "Creating a regex for street names, stored in street_type_re \n",
    "and a default dictionary that will include pairs of street names, \n",
    "where inconsistent abbreviations are matched with consistent terms.\n",
    "The following code audits the datafile to look for street names that \n",
    "have an ending that is different from the values in the expected list.\n",
    "\n",
    "'''\n",
    "OSM_FILE = \"full_map.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# List of expected street names.\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# Current values and what we would like to change them to.\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"CT\": \"Court\",\n",
    "            \"Ct.\": \"Court\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"BLVD\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"DR\": \"Drive\",\n",
    "           \" Ctr\": \" Centre\",\n",
    "            \" Pl \": \" Place \",\n",
    "            \" Ln \": \" Lane \",\n",
    "            \" Cir \": \" Circle \",\n",
    "            \" Wy\": \" Way \",\n",
    "            \" S \": \" South \",\n",
    "            \" E \": \" East \",\n",
    "            \" W \": \" West \",\n",
    "            \" N \": \"North\"\n",
    "          }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "            elem.clear()        \n",
    "    f.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    for key,value in mapping.items():\n",
    "        if key in name:\n",
    "            return name.replace(key,value)\n",
    "    return name        \n",
    "'''\n",
    "Using the smaller map.osm file as an input to audit the street name\n",
    "'''\n",
    "\n",
    "\n",
    "st_types = audit('map.osm')\n",
    "\n",
    "#pprint.pprint(dict(st_types))\n",
    "for st_type, ways in st_types.items():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print (name, \"=>\", better_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-pressing",
   "metadata": {},
   "source": [
    "Looks like the abbreviations for the street names in the smaller map.osm were corrected by the preceding code. Now, I will correct the abbreviations for the larger dataset: full_map.osm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "presidential-causing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Northeast 187th Way => Northeast 187th Way\n",
      "Alaskan Way => Alaskan Way\n",
      "Edmonds Way => Edmonds Way\n",
      "Northeast Perkins Way => Northeast Perkins Way\n",
      "NE Bothell Way => NE Bothell Way\n",
      "Northeast Bothell Way => Northeast Bothell Way\n",
      "McAleer Way => McAleer Way\n",
      "Lake Ballinger Way => Lake Ballinger Way\n",
      "Cedar Way => Cedar Way\n",
      "2nd Avenue Northeast => 2nd Avenuenue Northeast\n",
      "63rd Place Northeast => 63rd Place Northeast\n",
      "63rd Lane Northeast => 63rd Lane Northeast\n",
      "15th Avenue Northeast => 15th Avenuenue Northeast\n",
      "5th Avenue Northeast => 5th Avenuenue Northeast\n",
      "8th Avenue Northeast => 8th Avenuenue Northeast\n",
      "62nd Court Northeast => 62nd Court Northeast\n",
      "81st Avenue Northeast => 81st Avenuenue Northeast\n",
      "66th Court Northeast => 66th Court Northeast\n",
      "58th Lane Northeast => 58th Lane Northeast\n",
      "36th Court Northeast => 36th Court Northeast\n",
      "10th Avenue Northeast => 10th Avenuenue Northeast\n",
      "64th Place Northeast => 64th Place Northeast\n",
      "125th Avenue Northeast => 125th Avenuenue Northeast\n",
      "Erickson Place Northeast => Erickson Place Northeast\n",
      "3rd Avenue Northeast => 3rd Avenuenue Northeast\n",
      "60th Avenue Northeast => 60th Avenuenue Northeast\n",
      "45th Avenue Northeast => 45th Avenuenue Northeast\n",
      "65th Avenue Northeast => 65th Avenuenue Northeast\n",
      "35th Avenue Northeast => 35th Avenuenue Northeast\n",
      "25th Avenue Northeast => 25th Avenuenue Northeast\n",
      "58th Place Northeast => 58th Place Northeast\n",
      "14th Place Northeast => 14th Place Northeast\n",
      "42nd Place Northeast => 42nd Place Northeast\n",
      "72nd Avenue Northeast => 72nd Avenuenue Northeast\n",
      "69th Lane Northeast => 69th Lane Northeast\n",
      "Shore Drive Northeast => Shore Driveive Northeast\n",
      "81st Lane Northeast => 81st Lane Northeast\n",
      "65th Place Northeast => 65th Place Northeast\n",
      "61st Place Northeast => 61st Place Northeast\n",
      "75th Avenue Northeast => 75th Avenuenue Northeast\n",
      "16th Avenue Northeast => 16th Avenuenue Northeast\n",
      "71st Place Northeast => 71st Place Northeast\n",
      "77th Place Northeast => 77th Place Northeast\n",
      "62nd Way Northeast => 62nd Way Northeast\n",
      "66th Place Northeast => 66th Place Northeast\n",
      "70th Avenue Northeast => 70th Avenuenue Northeast\n",
      "74th Avenue Northeast => 74th Avenuenue Northeast\n",
      "33rd Avenue Northeast => 33rd Avenuenue Northeast\n",
      "74th Place Northeast => 74th Place Northeast\n",
      "80th Court Northeast => 80th Court Northeast\n",
      "79th Court Northeast => 79th Court Northeast\n",
      "11th Avenue Northeast => 11th Avenuenue Northeast\n",
      "Inglewood Terrace Northeast => Inglewood Terrace Northeast\n",
      "63rd Avenue Northeast => 63rd Avenuenue Northeast\n",
      "65th Court Northeast => 65th Court Northeast\n",
      "81st Court Northeast => 81st Court Northeast\n",
      "Westwood Place Northeast => Westwood Place Northeast\n",
      "70th Court Northeast => 70th Court Northeast\n",
      "62nd Avenue Northeast => 62nd Avenuenue Northeast\n",
      "1st Avenue Northeast => 1st Avenuenue Northeast\n",
      "67th Avenue Northeast => 67th Avenuenue Northeast\n",
      "64th Avenue Northeast => 64th Avenuenue Northeast\n",
      "76th Place Northeast => 76th Place Northeast\n",
      "77th Avenue Northeast => 77th Avenuenue Northeast\n",
      "17th Avenue Northeast => 17th Avenuenue Northeast\n",
      "32nd Avenue Northeast => 32nd Avenuenue Northeast\n",
      "66th Avenue Northeast => 66th Avenuenue Northeast\n",
      "Roosevelt Way Northeast => Roosevelt Way Northeast\n",
      "61st Lane Northeast => 61st Lane Northeast\n",
      "78th Place Northeast => 78th Place Northeast\n",
      "83rd Avenue Northeast => 83rd Avenuenue Northeast\n",
      "69th Place Northeast => 69th Place Northeast\n",
      "23rd Place Northeast => 23rd Place Northeast\n",
      "70th Lane Northeast => 70th Lane Northeast\n",
      "30th Avenue Northeast => 30th Avenuenue Northeast\n",
      "79th Place Northeast => 79th Place Northeast\n",
      "67th Place Northeast => 67th Place Northeast\n",
      "39th Avenue Northeast => 39th Avenuenue Northeast\n",
      "57th Avenue Northeast => 57th Avenuenue Northeast\n",
      "20th Avenue Northeast => 20th Avenuenue Northeast\n",
      "76th Avenue Northeast => 76th Avenuenue Northeast\n",
      "64th Court Northeast => 64th Court Northeast\n",
      "64th Lane Northeast => 64th Lane Northeast\n",
      "73rd Avenue Northeast => 73rd Avenuenue Northeast\n",
      "61st Court Northeast => 61st Court Northeast\n",
      "Par Place Northeast => Par Place Northeast\n",
      "Lake City Way Northeast => Lake City Way Northeast\n",
      "82nd Lane Northeast => 82nd Lane Northeast\n",
      "58th Avenue Northeast => 58th Avenuenue Northeast\n",
      "80th Place Northeast => 80th Place Northeast\n",
      "Inglewood Road Northeast => Inglewood Road Northeast\n",
      "84th Avenue Northeast => 84th Avenuenue Northeast\n",
      "Kenlake Place Northeast => Kenlake Place Northeast\n",
      "67th Lane Northeast => 67th Lane Northeast\n",
      "61st Avenue Northeast => 61st Avenuenue Northeast\n",
      "44th Avenue Northeast => 44th Avenuenue Northeast\n",
      "37th Avenue Northeast => 37th Avenuenue Northeast\n",
      "27th Avenue Northeast => 27th Avenuenue Northeast\n",
      "55th Avenue Northeast => 55th Avenuenue Northeast\n",
      "35th Court Northeast => 35th Court Northeast\n",
      "81st Place Northeast => 81st Place Northeast\n",
      "38th Avenue Northeast => 38th Avenuenue Northeast\n",
      "42nd Avenue Northeast => 42nd Avenuenue Northeast\n",
      "28th Avenue Northeast => 28th Avenuenue Northeast\n",
      "8th Court Northeast => 8th Court Northeast\n",
      "Bothell Way Northeast => Bothell Way Northeast\n",
      "83rd Court Northeast => 83rd Court Northeast\n",
      "82nd Court Northeast => 82nd Court Northeast\n",
      "47th Avenue Northeast => 47th Avenuenue Northeast\n",
      "72nd Court Northeast => 72nd Court Northeast\n",
      "Juanita Drive Northeast => Juanita Driveive Northeast\n",
      "72nd Place Northeast => 72nd Place Northeast\n",
      "80th Avenue Northeast => 80th Avenuenue Northeast\n",
      "Brookside Boulevard Northeast => Brookside Boulevard Northeast\n",
      "22nd Avenue Northeast => 22nd Avenuenue Northeast\n",
      "41st Avenue Northeast => 41st Avenuenue Northeast\n",
      "65th Lane Northeast => 65th Lane Northeast\n",
      "73rd Place Northeast => 73rd Place Northeast\n",
      "82nd Place Northeast => 82nd Place Northeast\n",
      "71st Avenue Northeast => 71st Avenuenue Northeast\n",
      "15th Place Northeast => 15th Place Northeast\n",
      "19th Avenue Northeast => 19th Avenuenue Northeast\n",
      "23rd Avenue Northeast => 23rd Avenuenue Northeast\n",
      "Ballinger Way Northeast => Ballinger Way Northeast\n",
      "26th Avenue Northeast => 26th Avenuenue Northeast\n",
      "56th Lane Northeast => 56th Lane Northeast\n",
      "76th Court Northeast => 76th Court Northeast\n",
      "24th Avenue Northeast => 24th Avenuenue Northeast\n",
      "56th Avenue Northeast => 56th Avenuenue Northeast\n",
      "82nd Avenue Northeast => 82nd Avenuenue Northeast\n",
      "Simonds Road Northeast => Simonds Road Northeast\n",
      "83rd Place Northeast => 83rd Place Northeast\n",
      "69th Avenue Northeast => 69th Avenuenue Northeast\n",
      "4th Avenue Northeast => 4th Avenuenue Northeast\n",
      "68th Avenue Northeast => 68th Avenuenue Northeast\n",
      "74th Court Northeast => 74th Court Northeast\n",
      "24th Place Northeast => 24th Place Northeast\n",
      "62nd Place Northeast => 62nd Place Northeast\n",
      "40th Avenue Northeast => 40th Avenuenue Northeast\n",
      "31st Drive Northeast => 31st Driveive Northeast\n",
      "Inglewood Place Northeast => Inglewood Place Northeast\n",
      "Riviera Place Northeast => Riviera Place Northeast\n",
      "12th Avenue Northeast => 12th Avenuenue Northeast\n",
      "78th Avenue Northeast => 78th Avenuenue Northeast\n",
      "79th Avenue Northeast => 79th Avenuenue Northeast\n",
      "Holmes Point Drive Northeast => Holmes Point Driveive Northeast\n",
      "73rd Court Northeast => 73rd Court Northeast\n",
      "59th Place Northeast => 59th Place Northeast\n",
      "31st Avenue Northeast => 31st Avenuenue Northeast\n",
      "36th Avenue Northeast => 36th Avenuenue Northeast\n",
      "60th Place Northeast => 60th Place Northeast\n",
      "Inglewood Lane Northeast => Inglewood Lane Northeast\n",
      "57th Place Northeast => 57th Place Northeast\n",
      "Aurora Ave North => Aurora Avenue North\n",
      "13754 Aurora Avenue North => 13754 Aurora Avenuenue North\n",
      "Whitman Avenue North => Whitman Avenuenue North\n",
      "Greenwood Avenue North => Greenwood Avenuenue North\n",
      "Phinney Avenue North => Phinney Avenuenue North\n",
      "Sunnyside Avenue North => Sunnyside Avenuenue North\n",
      "Roosevelt Way North => Roosevelt Way North\n",
      "Aurora Avenue North => Aurora Avenuenue North\n",
      "Linden Avenue North => Linden Avenuenue North\n",
      "Bitter Place North => Bitter Place North\n",
      "Midvale Avenue North => Midvale Avenuenue North\n",
      "Densmore Avenue North => Densmore Avenuenue North\n",
      "Wayne Place North => Wayne Place North\n",
      "Dayton Avenue North => Dayton Avenuenue North\n",
      "Wingard Court North => Wingard Court North\n",
      "Meridian Avenue North => Meridian Avenuenue North\n",
      "North Park Avenue North => North Park Avenuenue North\n",
      "Bagley Avenue North => Bagley Avenuenue North\n",
      "Lenora Place North => Lenora Place North\n",
      "Ashworth Avenue North => Ashworth Avenuenue North\n",
      "Wallingford Avenue North => Wallingford Avenuenue North\n",
      "Evanston Avenue North => Evanston Avenuenue North\n",
      "Westminster Way North => Westminster Way North\n",
      "Palatine Avenue North => Palatine Avenuenue North\n",
      "Fremont Avenue North => Fremont Avenuenue North\n",
      "Burke Avenue North => Burke Avenuenue North\n",
      "Roslyn Place North => Roslyn Place North\n",
      "Courtland Place North => Courtland Place North\n",
      "Stone Avenue North => Streetone Avenue North\n",
      "Interlake Avenue North => Interlake Avenuenue North\n",
      "Corliss Avenue North => Corliss Avenuenue North\n",
      "Blakely Place Northwest => Blakely Place Northwest\n",
      "22nd Avenue Northwest => 22nd Avenuenue Northwest\n",
      "Sherwood Road Northwest => Sherwood Road Northwest\n",
      "15th Avenue Northwest => 15th Avenuenue Northwest\n",
      "Juanita Drive Northwest => Juanita Driveive Northwest\n",
      "12th Avenue Northwest => 12th Avenuenue Northwest\n",
      "Richmond Beach Drive Northwest => Richmond Beach Driveive Northwest\n",
      "Hill Top Lane Northwest => Hill Top Lane Northwest\n",
      "6th Avenue Northwest => 6th Avenuenue Northwest\n",
      "10th Avenue Northwest => 10th Avenuenue Northwest\n",
      "11th Avenue Northwest => 11th Avenuenue Northwest\n",
      "4th Avenue Northwest => 4th Avenuenue Northwest\n",
      "Northwood Road Northwest => Northwood Road Northwest\n",
      "8th Avenue Northwest => 8th Avenuenue Northwest\n",
      "Sherman Road Northwest => Sherman Road Northwest\n",
      "Frazier Place Northwest => Frazier Place Northwest\n",
      "11th Place Northwest => 11th Place Northwest\n",
      "Northshire Road Northwest => Northshire Road Northwest\n",
      "Alpine Way Northwest => Alpine Way Northwest\n",
      "7th Avenue Northwest => 7th Avenuenue Northwest\n",
      "3rd Avenue Northwest => 3rd Avenuenue Northwest\n",
      "2nd Avenue Northwest => 2nd Avenuenue Northwest\n",
      "9th Avenue Northwest => 9th Avenuenue Northwest\n",
      "Northwood Place Northwest => Northwood Place Northwest\n",
      "13th Avenue Northwest => 13th Avenuenue Northwest\n",
      "1st Avenue Northwest => 1st Avenuenue Northwest\n",
      "244th Street Southwest => 244th Streetreet Southwest\n",
      "237th Street Southwest => 237th Streetreet Southwest\n",
      "232nd Place Southwest => 232nd Place Southwest\n",
      "232nd Street Southwest => 232nd Streetreet Southwest\n",
      "239th Street Southwest => 239th Streetreet Southwest\n",
      "North 205th Street - 244th Street Southwest => North 205th Streetreet - 244th Streetreet Southwest\n",
      "235th Place Southwest => 235th Place Southwest\n",
      "243rd Place Southwest => 243rd Place Southwest\n",
      "240th Street Southwest => 240th Streetreet Southwest\n",
      "234th Place Southwest => 234th Place Southwest\n",
      "241st Place Southwest => 241st Place Southwest\n",
      "235th Street Southwest => 235th Streetreet Southwest\n",
      "233rd Street Southwest => 233rd Streetreet Southwest\n",
      "238th Place Southwest => 238th Place Southwest\n",
      "237th Place Southwest => 237th Place Southwest\n",
      "238th Street Southwest => 238th Streetreet Southwest\n",
      "233rd Place Southwest => 233rd Place Southwest\n",
      "234th Street Southwest => 234th Streetreet Southwest\n",
      "242nd Place Southwest => 242nd Place Southwest\n",
      "236th Street Southwest => 236th Streetreet Southwest\n",
      "231st Place Southwest => 231st Place Southwest\n",
      "240th Place Southwest => 240th Place Southwest\n",
      "239th Place Southwest => 239th Place Southwest\n",
      "231st Street Southwest => 231st Streetreet Southwest\n",
      "241st Street Southwest => 241st Streetreet Southwest\n",
      "236th Place Southwest => 236th Place Southwest\n",
      "242nd Street Southwest => 242nd Streetreet Southwest\n",
      "Northwest Cherry Loop => Northwest Cherry Loop\n",
      "Highway 99 => Highway 99\n",
      "Richmond Beach Rd => Richmond Beach Road\n",
      "1st Avenue West => 1st Avenuenue West\n",
      "96th Avenue West => 96th Avenuenue West\n",
      "97th Place West => 97th Place West\n",
      "7th Place West => 7th Place West\n",
      "52nd Avenue West => 52nd Avenuenue West\n",
      "75th Avenue West => 75th Avenuenue West\n",
      "3rd Place West => 3rd Place West\n",
      "97th Avenue West => 97th Avenuenue West\n",
      "105th Place West => 105th Place West\n",
      "77th Place West => 77th Place West\n",
      "80th Lane West => 80th Lane West\n",
      "81st Place West => 81st Place West\n",
      "56th Avenue West => 56th Avenuenue West\n",
      "84th Avenue West => 84th Avenuenue West\n",
      "89th Avenue West => 89th Avenuenue West\n",
      "4th Place West => 4th Place West\n",
      "58th Avenue West => 58th Avenuenue West\n",
      "91st Avenue West => 91st Avenuenue West\n",
      "98th Avenue West => 98th Avenuenue West\n",
      "6th Place West => 6th Place West\n",
      "76th Place West => 76th Place West\n",
      "95th Place West => 95th Place West\n",
      "1st Place West => 1st Place West\n",
      "61st Avenue West => 61st Avenuenue West\n",
      "60th Avenue West => 60th Avenuenue West\n",
      "87th Place West => 87th Place West\n",
      "59th Avenue West => 59th Avenuenue West\n",
      "55th Avenue West => 55th Avenuenue West\n",
      "58th Place West => 58th Place West\n",
      "100th Avenue West => 100th Avenuenue West\n",
      "86th Avenue West => 86th Avenuenue West\n",
      "94th Avenue West => 94th Avenuenue West\n",
      "2nd Place West => 2nd Place West\n",
      "75th Place West => 75th Place West\n",
      "7th Avenue West => 7th Avenuenue West\n",
      "91st Place West => 91st Place West\n",
      "80th Avenue West => 80th Avenuenue West\n",
      "2nd Avenue West => 2nd Avenuenue West\n",
      "102nd Place West => 102nd Place West\n",
      "104th Place West => 104th Place West\n",
      "78th Avenue West => 78th Avenuenue West\n",
      "54th Avenue West => 54th Avenuenue West\n",
      "80th Way West => 80th Way West\n",
      "88th Avenue West => 88th Avenuenue West\n",
      "76th Avenue West => 76th Avenuenue West\n",
      "82nd Place West => 82nd Place West\n",
      "80th Court West => 80th Court West\n",
      "106th Avenue West => 106th Avenuenue West\n",
      "57th Place West => 57th Place West\n",
      "90th Avenue West => 90th Avenuenue West\n",
      "89th Place West => 89th Place West\n",
      "90th Place West => 90th Place West\n",
      "83rd Avenue West => 83rd Avenuenue West\n",
      "101st Avenue West => 101st Avenuenue West\n",
      "85th Avenue West => 85th Avenuenue West\n",
      "99th Place West => 99th Place West\n",
      "88th Place West => 88th Place West\n",
      "77th Avenue West => 77th Avenuenue West\n",
      "87th Avenue West => 87th Avenuenue West\n",
      "93rd Avenue West => 93rd Avenuenue West\n",
      "106th Place West => 106th Place West\n",
      "57th Avenue West => 57th Avenuenue West\n",
      "92nd Avenue West => 92nd Avenuenue West\n",
      "79th Place West => 79th Place West\n",
      "78th Place West => 78th Place West\n",
      "80th Place West => 80th Place West\n",
      "79th Avenue West => 79th Avenuenue West\n",
      "104th Avenue West => 104th Avenuenue West\n",
      "82nd Avenue West => 82nd Avenuenue West\n",
      "99th Avenue West => 99th Avenuenue West\n",
      "74th Avenue West => 74th Avenuenue West\n",
      "107th Place West => 107th Place West\n",
      "96th Place West => 96th Place West\n",
      "101st Place West => 101st Place West\n",
      "5th Avenue West => 5th Avenuenue West\n",
      "102nd Avenue West => 102nd Avenuenue West\n",
      "94th Place West => 94th Place West\n",
      "59th Place West => 59th Place West\n",
      "86th Place West => 86th Place West\n",
      "Meridian Place West => Meridian Place West\n",
      "53rd Avenue West => 53rd Avenuenue West\n",
      "25th Ave NE => 25th Avenue NE\n",
      "Ballinger Way NE => Ballinger Way NE\n",
      "68th Ave NE => 68th Avenue NE\n",
      "5th Ave NE => 5th Avenue NE\n",
      "18336 AURORA AVE N => 18336 AURORA AVE N\n",
      "231st Street Southeast => 231st Streetreet Southeast\n",
      "240th Street Southeast => 240th Streetreet Southeast\n",
      "232nd Place Southeast => 232nd Place Southeast\n",
      "3rd Avenue Southeast => 3rd Avenuenue Southeast\n",
      "235th Place Southeast => 235th Place Southeast\n",
      "243rd Place Southeast => 243rd Place Southeast\n",
      "233rd Place Southeast => 233rd Place Southeast\n",
      "236th Street Southeast => 236th Streetreet Southeast\n",
      "239th Street Southeast => 239th Streetreet Southeast\n",
      "236th Place Southeast => 236th Place Southeast\n",
      "1st Avenue Southeast => 1st Avenuenue Southeast\n",
      "234th Place Southeast => 234th Place Southeast\n",
      "2nd Avenue Southeast => 2nd Avenuenue Southeast\n",
      "242nd Street Southeast => 242nd Streetreet Southeast\n",
      "Meridian Avenue South => Meridian Avenuenue South\n",
      "56th Ave W => 56th Avenue W\n",
      "NE 185th St => NE 185th Street\n",
      "NE 205th St => NE 205th Street\n",
      "NE 158th St => NE 158th Street\n",
      "236th St SW => 236th Street SW\n",
      "N 202nd Pl => N 202nd Pl\n"
     ]
    }
   ],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# List of expected street names.\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# Current values and what we would like to change them to.\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"CT\": \"Court\",\n",
    "            \"Ct.\": \"Court\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"BLVD\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"DR\": \"Drive\",\n",
    "           \" Ctr\": \" Centre\",\n",
    "            \" Pl \": \" Place \",\n",
    "            \" Ln \": \" Lane \",\n",
    "            \" Cir \": \" Circle \",\n",
    "            \" Wy\": \" Way \",\n",
    "            \" S \": \" South \",\n",
    "            \" E \": \" East \",\n",
    "            \" W \": \" West \",\n",
    "            \" N \": \"North\"\n",
    "          }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "            elem.clear()        \n",
    "    f.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    for key,value in mapping.items():\n",
    "        if key in name:\n",
    "            return name.replace(key,value)\n",
    "    return name        \n",
    "'''\n",
    "Using the full_map.osm file as an input to audit street abbreviations.\n",
    "'''\n",
    "\n",
    "\n",
    "st_types = audit('full_map.osm')\n",
    "\n",
    "#pprint.pprint(dict(st_types))\n",
    "for st_type, ways in st_types.items():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print (name, \"=>\", better_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-screening",
   "metadata": {},
   "source": [
    "## Preparing data to create csv files and SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-analysis",
   "metadata": {},
   "source": [
    "### Running the schema file provided in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "opposite-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema code provided by Udacity.\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "southern-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "OSM_PATH = \"full_map.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "excess-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "   # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in NODE_FIELDS:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "        \n",
    "        for child in element:\n",
    "            node_tag = {}\n",
    "            if LOWER_COLON.match(child.attrib['k']):\n",
    "                node_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                node_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                tags.append(node_tag)\n",
    "            elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                continue\n",
    "            else:\n",
    "                node_tag['type'] = 'regular'\n",
    "                node_tag['key'] = child.attrib['k']\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                tags.append(node_tag)\n",
    "        \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "        \n",
    "    elif element.tag == 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in WAY_FIELDS:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "        \n",
    "        position = 0\n",
    "        for child in element:\n",
    "            way_tag = {}\n",
    "            way_node = {}\n",
    "            \n",
    "            if child.tag == 'tag':\n",
    "                if LOWER_COLON.match(child.attrib['k']):\n",
    "                    way_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                    way_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    tags.append(way_tag)\n",
    "                elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                    continue\n",
    "                else:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    way_tag['key'] = child.attrib['k']\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    tags.append(way_tag)\n",
    "                    \n",
    "            elif child.tag == 'nd':\n",
    "                way_node['id'] = element.attrib['id']\n",
    "                way_node['node_id'] = child.attrib['ref']\n",
    "                way_node['position'] = position\n",
    "                position += 1\n",
    "                way_nodes.append(way_node)\n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-stamp",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "alternate-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting and validating the element.\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "#Unidcode dictwriter\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "             k: (v.encode('utf-8') if isinstance(v, str) else v) for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-glass",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fatal-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for creating csv files.\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w', \"utf-8\") as nodes_file, \\\n",
    "     codecs.open(NODE_TAGS_PATH, 'w', \"utf-8\") as nodes_tags_file, \\\n",
    "     codecs.open(WAYS_PATH, 'w', \"utf-8\") as ways_file, \\\n",
    "     codecs.open(WAY_NODES_PATH, 'w', \"utf-8\") as way_nodes_file, \\\n",
    "     codecs.open(WAY_TAGS_PATH, 'w', \"utf-8\") as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-present",
   "metadata": {},
   "source": [
    "# Data Overview and Additional Ideas\n",
    "______________________________________________________\n",
    "\n",
    "#### This section contains:\n",
    "* Code for cleaning up problems in the csv files.\n",
    "* Code for creating a database.\n",
    "* Basic statistics about the dataset.\n",
    "* SQL queries used to gather statistics.\n",
    "* Additional ideas for using the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "arbitrary-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "precious-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv('nodes.csv')\n",
    "nodes_tags = pd.read_csv('nodes_tags.csv')\n",
    "ways = pd.read_csv('ways.csv')\n",
    "ways_nodes = pd.read_csv('ways_nodes.csv')\n",
    "ways_tags = pd.read_csv('ways_tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-sender",
   "metadata": {},
   "source": [
    "### Checking out the size of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "judicial-acoustic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is TI10673200G\n",
      " Volume Serial Number is 5E9D-3D3F\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "04/08/2021  11:38 AM        32,118,943 nodes.csv\n",
      "               1 File(s)     32,118,943 bytes\n",
      "               0 Dir(s)  592,109,125,632 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls -s nodes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "legendary-joining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is TI10673200G\n",
      " Volume Serial Number is 5E9D-3D3F\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "04/08/2021  11:38 AM         1,449,073 nodes_tags.csv\n",
      "               1 File(s)      1,449,073 bytes\n",
      "               0 Dir(s)  592,108,994,560 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls -s nodes_tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "blond-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is TI10673200G\n",
      " Volume Serial Number is 5E9D-3D3F\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "04/08/2021  11:38 AM         3,189,719 ways.csv\n",
      "               1 File(s)      3,189,719 bytes\n",
      "               0 Dir(s)  592,108,994,560 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls -s ways.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "interim-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is TI10673200G\n",
      " Volume Serial Number is 5E9D-3D3F\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "04/08/2021  11:38 AM         9,768,360 ways_nodes.csv\n",
      "               1 File(s)      9,768,360 bytes\n",
      "               0 Dir(s)  592,108,847,104 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls -s ways_nodes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "aggregate-construction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is TI10673200G\n",
      " Volume Serial Number is 5E9D-3D3F\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\Rob\n",
      "\n",
      "04/08/2021  11:38 AM         7,260,986 ways_tags.csv\n",
      "               1 File(s)      7,260,986 bytes\n",
      "               0 Dir(s)  592,108,797,952 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls -s ways_tags.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-angel",
   "metadata": {},
   "source": [
    "### File sizes\n",
    "______________________________________________________\n",
    "\n",
    "full_map.osm......... 69.0 MB\n",
    "\n",
    "nodes.csv.............. 32.0 MB\n",
    "\n",
    "nodes_tags.csv.......  1.4 MB\n",
    "\n",
    "ways.csv.................. 3.2 MB\n",
    "\n",
    "ways_nodes.csv......  9.8 MB\n",
    "\n",
    "ways_tags.csv.........  7.2 MB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-proof",
   "metadata": {},
   "source": [
    "### Cleaning up problems encountered with the csv files.\n",
    "\n",
    "After creating the csv files, I noticed that all of the values (including column headings) had a \"b\" appended before each value. I wrote the following code to correct the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "excess-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=nodes.rename(columns={\"b'id'\":\"id\"})\n",
    "nodes=nodes.rename(columns={\"b'lat'\":\"lat\"})\n",
    "nodes=nodes.rename(columns={\"b'lon'\":\"lon\"})\n",
    "nodes=nodes.rename(columns={\"b'user'\":\"user\"})\n",
    "nodes=nodes.rename(columns={\"b'uid'\":\"uid\"})\n",
    "nodes=nodes.rename(columns={\"b'version'\":\"version\"})\n",
    "nodes=nodes.rename(columns={\"b'changeset'\":\"changeset\"})\n",
    "nodes=nodes.rename(columns={\"b'timestamp'\":\"timestamp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "following-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_tags=nodes_tags.rename(columns={\"b'id'\":\"id\"})\n",
    "nodes_tags=nodes_tags.rename(columns={\"b'key'\":\"key\"})\n",
    "nodes_tags=nodes_tags.rename(columns={\"b'value'\":\"value\"})\n",
    "nodes_tags=nodes_tags.rename(columns={\"b'type'\":\"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "similar-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways=ways.rename(columns={\"b'id'\":\"id\"})\n",
    "ways=ways.rename(columns={\"b'changeset'\":\"changeset\"})\n",
    "ways=ways.rename(columns={\"b'timestamp'\":\"timestamp\"})\n",
    "ways=ways.rename(columns={\"b'user'\":\"user\"})\n",
    "ways=ways.rename(columns={\"b'uid'\":\"uid\"})\n",
    "ways=ways.rename(columns={\"b'version'\":\"version\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fallen-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_nodes=ways_nodes.rename(columns={\"b'id'\":\"id\"})\n",
    "ways_nodes=ways_nodes.rename(columns={\"b'node_id'\":\"node_id\"})\n",
    "ways_nodes=ways_nodes.rename(columns={\"b'position'\":\"position\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "loving-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_tags=ways_tags.rename(columns={\"b'id'\":\"id\"})\n",
    "ways_tags=ways_tags.rename(columns={\"b'key'\":\"key\"})\n",
    "ways_tags=ways_tags.rename(columns={\"b'value'\":\"value\"})\n",
    "ways_tags=ways_tags.rename(columns={\"b'type'\":\"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "differential-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes['ID'] = nodes.ID.str[1:]\n",
    "nodes['lat'] = nodes.lat.str[1:]\n",
    "nodes['lon'] = nodes.lon.str[1:]\n",
    "nodes['user'] = nodes.user.str[1:]\n",
    "nodes['uid'] = nodes.uid.str[1:]\n",
    "nodes['version'] = nodes.version.str[1:]\n",
    "nodes['changeset'] = nodes.changeset.str[1:]\n",
    "nodes['timestamp'] = nodes.timestamp.str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "brown-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_tags['id'] = nodes_tags.id.str[1:]\n",
    "nodes_tags['key'] = nodes_tags.key.str[1:]\n",
    "nodes_tags['value'] = nodes_tags.value.str[1:]\n",
    "nodes_tags['type'] = nodes_tags.type.str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "tired-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways['id'] = ways.id.str[1:]\n",
    "ways['user'] = ways.user.str[1:]\n",
    "ways['uid'] = ways.uid.str[1:]\n",
    "ways['version'] = ways.version.str[1:]\n",
    "ways['changeset'] = ways.changeset.str[1:]\n",
    "ways['timestamp'] = ways.timestamp.str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "friendly-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_nodes['id'] = ways_nodes.id.str[1:]\n",
    "ways_nodes['node_id'] = ways_nodes.node_id.str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "meaningful-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_tags['id'] = ways_tags.id.str[1:]\n",
    "ways_tags['key'] = ways_tags.key.str[1:]\n",
    "ways_tags['value'] = ways_tags.value.str[1:]\n",
    "ways_tags['type'] = ways_tags.type.str[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-boost",
   "metadata": {},
   "source": [
    "### Creating the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "leading-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite://', echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-speaker",
   "metadata": {},
   "source": [
    "### Creating 'nodes' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "expected-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.to_sql('nodes', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-queens",
   "metadata": {},
   "source": [
    "### Number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "found-values",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(282515,)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT count(DISTINCT(id)) FROM nodes;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-spiritual",
   "metadata": {},
   "source": [
    "### Creating 'nodes_tags' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "public-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_tags.to_sql('nodes_tags', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-organic",
   "metadata": {},
   "source": [
    "### Number of node tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "special-patch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8950,)]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT count(DISTINCT(id)) FROM nodes_tags;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-banner",
   "metadata": {},
   "source": [
    "### Creating 'ways' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fifteen-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways.to_sql('ways', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-shoot",
   "metadata": {},
   "source": [
    "### Number of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "impressive-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38728,)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT count(DISTINCT(id)) FROM ways;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-immigration",
   "metadata": {},
   "source": [
    "### Creating 'ways_nodes' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fiscal-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_nodes.to_sql('ways_nodes', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-catch",
   "metadata": {},
   "source": [
    "### Number of ways nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "virgin-canberra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38728,)]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT count(DISTINCT(id)) FROM ways_nodes;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-crash",
   "metadata": {},
   "source": [
    "### Creating 'ways_tags' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "olympic-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_tags.to_sql('ways_tags', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-tissue",
   "metadata": {},
   "source": [
    "### Number of ways tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "super-seafood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38535,)]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT count(DISTINCT(id)) FROM ways_tags;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-actress",
   "metadata": {},
   "source": [
    "### Number of unique users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "loaded-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(879,)]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT COUNT(DISTINCT(e.uid))FROM (SELECT uid FROM Nodes UNION ALL SELECT uid FROM Ways) as e;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-attempt",
   "metadata": {},
   "source": [
    "### Top 10 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "naughty-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'SeattleImport'\", 70247),\n",
       " (\"'patricknoll_import'\", 51383),\n",
       " (\"'AndrewKvalheim_import'\", 33121),\n",
       " (\"'Natfoot'\", 17282),\n",
       " (\"'Glassman_Import'\", 12816),\n",
       " (\"'Glassman'\", 11718),\n",
       " (\"'STBrenden'\", 6970),\n",
       " (\"'sctrojan79'\", 5387),\n",
       " (\"'compdude'\", 4525),\n",
       " (\"'KiloCrimson'\", 4036)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-jamaica",
   "metadata": {},
   "source": [
    "### Node type and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "demographic-intranet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'addr'\", 16150),\n",
       " (\"'regular'\", 11922),\n",
       " (\"'gtfs'\", 554),\n",
       " (\"'source'\", 177),\n",
       " (\"'brand'\", 145),\n",
       " (\"'gnis'\", 139),\n",
       " (\"'survey'\", 88),\n",
       " (\"'seamark'\", 51),\n",
       " (\"'contact'\", 32),\n",
       " (\"'railway'\", 24),\n",
       " (\"'bridge'\", 22),\n",
       " (\"'sdot'\", 16),\n",
       " (\"'checked_exists'\", 15),\n",
       " (\"'name'\", 11),\n",
       " (\"'ref'\", 9),\n",
       " (\"'opening_hours'\", 9),\n",
       " (\"'recycling'\", 7),\n",
       " (\"'construction'\", 6),\n",
       " (\"'traffic_signals'\", 5),\n",
       " (\"'tower'\", 4),\n",
       " (\"'service'\", 4),\n",
       " (\"'operator'\", 3),\n",
       " (\"'healthcare'\", 3),\n",
       " (\"'check_date'\", 3),\n",
       " (\"'census'\", 3),\n",
       " (\"'crossing'\", 2),\n",
       " (\"'toilets'\", 1),\n",
       " (\"'social_facility'\", 1),\n",
       " (\"'payment'\", 1),\n",
       " (\"'fire_hydrant'\", 1),\n",
       " (\"'disused'\", 1),\n",
       " (\"'diet'\", 1),\n",
       " (\"'communication'\", 1),\n",
       " (\"'capacity'\", 1),\n",
       " (\"'building'\", 1),\n",
       " (\"'access'\", 1),\n",
       " (\"'abandoned'\", 1)]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT type , count(*) as num  FROM nodes_tags group by type order by num desc;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-fiber",
   "metadata": {},
   "source": [
    "### Cuisine types and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "legendary-carolina",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'coffee_shop'\", 24),\n",
       " (\"'pizza'\", 16),\n",
       " (\"'sandwich'\", 14),\n",
       " (\"'burger'\", 12),\n",
       " (\"'mexican'\", 11),\n",
       " (\"'chinese'\", 9),\n",
       " (\"'american'\", 7),\n",
       " (\"'thai'\", 6),\n",
       " (\"'vietnamese'\", 4),\n",
       " (\"'mediterranean'\", 3),\n",
       " (\"'korean'\", 3),\n",
       " (\"'chicken'\", 3),\n",
       " (\"'tex-mex'\", 2),\n",
       " (\"'seafood'\", 2),\n",
       " (\"'frozen_yogurt'\", 2),\n",
       " (\"'barbecue'\", 2),\n",
       " (\"'asian'\", 2),\n",
       " (\"'vietnamese;sandwich;bubble_tea;boba;coffe;milkshake'\", 1),\n",
       " (\"'teriyaki'\", 1),\n",
       " (\"'taiwanese'\", 1)]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"select value,count(*) as num from (select key,value from nodes_tags UNION ALL select key,value from ways_tags) as e where e.key like '%cuisine%' group by value order by num desc limit 20;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-catholic",
   "metadata": {},
   "source": [
    "### Looking for nodes and ways tags associated with the light rail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "geological-findings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(158,)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"select count(*) from (select key,value from nodes_tags UNION ALL select key,value from ways_tags) as e  where key like '%rail%';\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "legislative-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'abandoned'\", 62),\n",
       " (\"'construction'\", 19),\n",
       " (\"'light_rail'\", 18),\n",
       " (\"'switch'\", 11),\n",
       " (\"'signal'\", 11),\n",
       " (\"'rail'\", 10),\n",
       " (\"'razed'\", 6),\n",
       " (\"'station'\", 4),\n",
       " (\"'level_crossing'\", 3),\n",
       " (\"'derail'\", 3),\n",
       " (\"'yes'\", 2),\n",
       " (\"'site'\", 2),\n",
       " (\"'crossing'\", 2),\n",
       " (\"'bad'\", 2),\n",
       " (\"'intermediate'\", 1),\n",
       " (\"'excellent'\", 1),\n",
       " (\"'buffer_stop'\", 1)]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"select value,count(*) as num from (select key,value from nodes_tags UNION ALL select key,value from ways_tags) as e where e.key like '%rail%' group by value order by num desc limit 20;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-praise",
   "metadata": {},
   "source": [
    "### Looking for nodes and ways tags associated with other public transit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "hidden-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(419,)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"select count(*) from (select key,value from nodes_tags UNION ALL select key,value from ways_tags) as e  where key like '%bus%';\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-bennett",
   "metadata": {},
   "source": [
    "### Percentage of nodes containing references to public transit.\n",
    "\n",
    "Based on the preceding two queries, about 0.002% of nodes (577/282,515) contain information pertaining to public transit, which in this case includes the light rail and city buses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-variation",
   "metadata": {},
   "source": [
    "\n",
    "### Ideas for additional improvements\n",
    "\n",
    "Information concerning proximinity to public transit could be added to the dataset for each node. Each node includes a pair of coordinates in lat/lon. In QGIS, an OSM tool exists that will batch process the distance between all of the points (i.e. nodes) in one dataset and all of the points in another dataset. That data could be added for each node in the dataset, along with the type of transit, so that a user could find the nearest light rail station to their favorite coffee shop for example.\n",
    "\n",
    "### Anticipated problems in implementing the improvement\n",
    "\n",
    "It would take an enormous amount of time to batch process the above mentioned data in QGIS. If multiple users broke the dataset up into smaller parts and each ran a batch process, it likely could be done quickly and without frying any computers.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "My Shoreline, Washington dataset was moderately large, but was relatively clean considering almost 900 users contributed to creating the OSM. Additional changes would likely improve the cleanliness of the data; however, the data isn't in bad shape now. As mentioned above, one potential improvement might be the inclusion of a proximinity to public transit stat for each node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-nepal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_env] *",
   "language": "python",
   "name": "conda-env-py3_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
